# ğŸš€ Guide de DÃ©marrage Rapide - Sprint 1

## âš¡ TL;DR - DÃ©marrage en 5 minutes

```bash
# 1. Clone et setup
git clone <votre-repo>
cd nlp-chatbot-project

# 2. Installation complÃ¨te
make quickstart

# 3. Lancer l'API
make serve

# 4. Tester
make api-test
```

**C'est tout !** ğŸ‰

---

## ğŸ“ Copier les Fichiers

Copiez tous les fichiers fournis dans cette structure :

```
nlp-chatbot-project/
â”œâ”€â”€ Makefile                          # â† Artifact "sprint1_makefile"
â”œâ”€â”€ docker-compose.yml                # â† Artifact "sprint1_setup"
â”œâ”€â”€ README.md                         # â† Artifact "sprint1_readme"
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ requirements.txt              # â† Artifact "sprint1_setup"
â”‚   â”œâ”€â”€ .env                          # â† Copier de .env.example
â”‚   â”œâ”€â”€ run.py                        # â† Artifact "us13_inference_api"
â”‚   â”‚
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                   # â† Artifact "us13_inference_api"
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py             # â† Artifact "sprint1_setup"
â”‚   â”‚   â”‚   â”œâ”€â”€ intents.py            # â† Artifact "us11_data_collection"
â”‚   â”‚   â”‚   â””â”€â”€ logging_config.py     # â† Artifact "sprint1_setup"
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ intent_classifier.py  # â† Artifact "us12_model_training"
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ nlu_service.py        # â† Artifact "us13_inference_api"
â”‚   â”‚   â”‚   â””â”€â”€ training_service.py   # â† Artifact "us12_model_training"
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ routes.py             # â† Artifact "us13_inference_api"
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ create_dataset.py         # â† Artifact "us11_data_collection"
â”‚   â”‚
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ conftest.py               # â† Artifact "sprint1_tests"
â”‚       â”œâ”€â”€ test_intent_classifier.py # â† Artifact "sprint1_tests"
â”‚       â”œâ”€â”€ test_nlu_service.py       # â† Artifact "sprint1_tests"
â”‚       â”œâ”€â”€ test_api.py               # â† Artifact "sprint1_tests"
â”‚       â”œâ”€â”€ test_dataset.py           # â† Artifact "sprint1_tests"
â”‚       â””â”€â”€ test_integration.py       # â† Artifact "sprint1_tests"
â”‚
â””â”€â”€ notebooks/
    â””â”€â”€ sprint1_demo.ipynb            # â† Artifact "sprint1_notebook"
```

---

## ğŸ› ï¸ Workflow DÃ©taillÃ©

### Ã‰tape 1 : Installation

```bash
# CrÃ©er environnement virtuel et installer dÃ©pendances
make install

# Ou manuellement :
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
python -m spacy download fr_core_news_lg
```

### Ã‰tape 2 : Services Docker

```bash
# DÃ©marrer PostgreSQL, Redis, MLflow
make docker-up

# VÃ©rifier status
make docker-status

# Voir logs
make docker-logs
```

### Ã‰tape 3 : Dataset

```bash
# CrÃ©er le dataset (seed + augmentation)
make dataset

# Voir statistiques
make dataset-stats

# Visualiser exemples
make dataset-view
```

**RÃ©sultat attendu** :
```
âœ… Loaded 50 seed examples
ğŸ”„ Starting data augmentation...
âœ… Generated 550+ augmented examples
ğŸ“Š Total dataset size: 600+

ğŸ“Š Dataset split:
  Train: 420 (70%)
  Val:   90 (15%)
  Test:  90 (15%)
```

### Ã‰tape 4 : EntraÃ®nement

```bash
# EntraÃ®ner le modÃ¨le (5 epochs)
make train

# Voir rÃ©sultats
make train-stats

# Ouvrir MLflow UI
make mlflow
```

**DurÃ©e** : 15-20 min (CPU) ou 3-5 min (GPU)

**MÃ©triques attendues** :
```
âœ… Val Accuracy: >85%
âœ… Val F1 Score: >0.85
âœ… Test Accuracy: >85%
```

### Ã‰tape 5 : Lancer l'API

```bash
# DÃ©marrer FastAPI en mode dev
make serve

# L'API sera sur http://localhost:8000
# Docs sur http://localhost:8000/docs
```

### Ã‰tape 6 : Tester

```bash
# Tests manuels de l'API
make api-test

# Tests automatisÃ©s
make test

# Tests avec coverage
make test-cov
```

---

## ğŸ§ª Exemples d'Utilisation

### cURL

```bash
# Classification simple
curl -X POST http://localhost:8000/api/nlp/classify \
  -H "Content-Type: application/json" \
  -d '{"text": "OÃ¹ est ma commande ?"}'

# RÃ©ponse :
{
  "intent": "track_order",
  "confidence": 0.94,
  "all_intents": {
    "track_order": 0.94,
    "return_request": 0.03,
    "product_inquiry": 0.01,
    "payment_issue": 0.01,
    "greeting": 0.01
  },
  "from_cache": false,
  "processing_time_ms": 45.2
}
```

### Python

```python
import httpx
import asyncio

async def classify(text):
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/api/nlp/classify",
            json={"text": text}
        )
        return response.json()

# Utilisation
result = asyncio.run(classify("Je veux retourner un article"))
print(f"Intent: {result['intent']}")
print(f"Confidence: {result['confidence']:.2%}")
```

### JavaScript / Node.js

```javascript
const axios = require('axios');

async function classify(text) {
  const response = await axios.post('http://localhost:8000/api/nlp/classify', {
    text: text
  });
  return response.data;
}

// Utilisation
classify("Bonjour").then(result => {
  console.log(`Intent: ${result.intent}`);
  console.log(`Confidence: ${(result.confidence * 100).toFixed(1)}%`);
});
```

---

## ğŸ“Š VÃ©rifier les RÃ©sultats

### 1. Dataset

```bash
# Voir statistiques
cat backend/data/processed/metadata.json | python -m json.tool

# Visualisations
open backend/data/processed/train_analysis.png
```

### 2. ModÃ¨le

```bash
# Configuration du modÃ¨le
cat backend/models/best_model/config.json | python -m json.tool

# Confusion matrix
open backend/models/confusion_matrix.png
```

### 3. MLflow

Ouvrir http://localhost:5000

Vous verrez :
- ğŸ“Š MÃ©triques d'entraÃ®nement (accuracy, loss, F1)
- ğŸ“ˆ Graphiques d'Ã©volution
- ğŸ”§ HyperparamÃ¨tres
- ğŸ’¾ ModÃ¨les sauvegardÃ©s

### 4. API

Ouvrir http://localhost:8000/docs

Documentation interactive Swagger :
- ğŸ§ª Tester tous les endpoints
- ğŸ“– Voir schÃ©mas de requÃªte/rÃ©ponse
- ğŸ” Explorer les modÃ¨les Pydantic

---

## ğŸ¯ CritÃ¨res de SuccÃ¨s

### US-1.1 - Dataset âœ…

- [x] 100+ exemples par intent
- [x] Format JSON standardisÃ©
- [x] Split 70/15/15
- [x] Data augmentation appliquÃ©e
- [x] Documentation + visualisations

**Commande de vÃ©rification** :
```bash
make dataset-stats
```

### US-1.2 - ModÃ¨le âœ…

- [x] Accuracy > 85% sur validation
- [x] Support FR et EN
- [x] Temps infÃ©rence < 100ms
- [x] ModÃ¨le versionnÃ© MLflow
- [x] Confusion matrix

**Commande de vÃ©rification** :
```bash
make train-stats
make mlflow
```

### US-1.3 - API âœ…

- [x] Endpoint POST /api/nlp/classify
- [x] Validation Pydantic
- [x] Cache Redis
- [x] Logging structurÃ©
- [x] Tests unitaires
- [x] Documentation OpenAPI

**Commande de vÃ©rification** :
```bash
make api-test
make test
```

---

## ğŸ› ProblÃ¨mes FrÃ©quents

### 1. Module not found

```bash
# VÃ©rifier que venv est activÃ©
which python  # Doit pointer vers venv/bin/python

# RÃ©activer
source backend/venv/bin/activate
```

### 2. Redis connection refused

```bash
# VÃ©rifier Docker
docker-compose ps

# RedÃ©marrer Redis
docker-compose restart redis
```

### 3. ModÃ¨le non trouvÃ©

```bash
# VÃ©rifier que l'entraÃ®nement est terminÃ©
ls -la backend/models/best_model/

# Si absent, rÃ©entraÃ®ner
make train
```

### 4. Port 8000 dÃ©jÃ  utilisÃ©

```bash
# Trouver le processus
lsof -i :8000

# Tuer le processus
kill -9 <PID>

# Ou changer le port dans .env
PORT=8001
```

### 5. Dataset trop petit

```python
# Ã‰diter backend/data/create_dataset.py
# Ligne ~90, augmenter le facteur
creator.augment_data(augmentation_factor=15)  # Au lieu de 10
```

---

## ğŸ“ˆ Performances Attendues

### ModÃ¨le

| MÃ©trique | Target | RÃ©sultat Attendu |
|----------|--------|------------------|
| Accuracy | >85% | ~90% |
| F1 Score | >85% | ~89% |
| Inference | <100ms | ~50ms |

### API

| MÃ©trique | Valeur |
|----------|--------|
| Latence sans cache | ~50ms |
| Latence avec cache | ~5-10ms |
| Throughput | ~20 req/s (CPU) |
| Cache hit rate | ~70% aprÃ¨s warmup |

### Dataset

| Split | Taille | Ratio |
|-------|--------|-------|
| Train | ~420 | 70% |
| Val | ~90 | 15% |
| Test | ~90 | 15% |
| **Total** | **~600** | **100%** |

---

## ğŸ”— URLs Utiles

| Service | URL | Description |
|---------|-----|-------------|
| API | http://localhost:8000 | API FastAPI |
| Docs | http://localhost:8000/docs | Documentation Swagger |
| ReDoc | http://localhost:8000/redoc | Documentation alternative |
| MLflow | http://localhost:5000 | Tracking ML |
| Health | http://localhost:8000/health | Health check |
| Stats | http://localhost:8000/api/nlp/stats | Statistiques cache |

---

## ğŸ“ Prochaines Ã‰tapes

### Sprint 2 Preview

1. **NER (Named Entity Recognition)**
   - Extraction ORDER_ID, DATE, MONEY
   - Fine-tuning Spacy

2. **Sentiment Analysis**
   - Classification positif/neutre/nÃ©gatif
   - DÃ©tection d'urgence

3. **Dialog Management**
   - Gestion contexte conversationnel
   - Multi-turn conversations

---

## ğŸ“š Resources

### Documentation
- [FastAPI](https://fastapi.tiangolo.com/)
- [PyTorch](https://pytorch.org/)
- [Transformers](https://huggingface.co/docs/transformers)
- [MLflow](https://mlflow.org/)

### ModÃ¨les
- [CamemBERT](https://huggingface.co/camembert-base)
- [Spacy French](https://spacy.io/models/fr)

---

## ğŸ’¡ Commandes Make Utiles

```bash
make help           # Voir toutes les commandes
make status         # VÃ©rifier status complet
make quickstart     # Setup + Dataset + Train (tout en un)
make clean          # Nettoyer fichiers temporaires
make reset          # Reset complet
```

---

## âœ… Checklist Finale

Avant de passer au Sprint 2, vÃ©rifiez :

- [ ] Dataset crÃ©Ã© (600+ exemples)
- [ ] ModÃ¨le entraÃ®nÃ© (accuracy >85%)
- [ ] API fonctionne (tests passent)
- [ ] Cache Redis opÃ©rationnel
- [ ] MLflow accessible
- [ ] Tests passent (>80% coverage)
- [ ] Documentation Ã  jour

**Commande de vÃ©rification complÃ¨te** :
```bash
make status
make test
```

---

## ğŸ‰ FÃ©licitations !

Vous avez complÃ©tÃ© le **Sprint 1 - NLU Foundation** !

**CompÃ©tences acquises** :
- âœ… CrÃ©ation et augmentation de datasets
- âœ… Fine-tuning de modÃ¨les Transformers
- âœ… API REST avec FastAPI
- âœ… Cache multi-niveaux (Redis + Memory)
- âœ… MLOps avec MLflow
- âœ… Tests automatisÃ©s

**Story Points complÃ©tÃ©s** : 42 SP

**Temps estimÃ©** : 2-3 heures (si tout se passe bien)

---

## ğŸ†˜ Besoin d'Aide ?

- ğŸ“– Consultez le [README complet](README.md)
- ğŸ› VÃ©rifiez [Troubleshooting](#-problÃ¨mes-frÃ©quents)
- ğŸ’¬ CrÃ©ez une issue sur GitHub
- ğŸ“§ Contactez l'Ã©quipe

---

**Bon dÃ©veloppement ! ğŸš€**